#Introducation
本系列为爬虫学习的笔记。通过一步一步分析和代码编写，从基础上描述了如何抓取网站。文章没有使用爬虫框架，而是使用最基础的requests（可视为简单的对urllib,urllib2封装，使得代码写起来更流畅，更pythonic）,从基础知识上进行操作。

# [一、分析ajax请求](http://www.findspace.name/easycoding/1627)
本文简述了分析某个网站的流程，查看是否是ajax的请求
# [二、分析post请求](http://www.findspace.name/easycoding/1628)
本文分析了ajax时，post请求的数据，并进行简单的解释说明
# [三、抓取页面](http://www.findspace.name/easycoding/1631)
本文在实验环境下，抓取了某个ajax页面
# [四、获取cookie](http://www.findspace.name/easycoding/1633)
本文简单说明了网站的反爬虫机制cookie，以及session。
# [五、获取特殊验证值](http://www.findspace.name/easycoding/1637)
本文描述了如果抓住蛛丝马迹获取网站一些特殊的验证值
# [六、requests 关于cookie的堪误](http://www.findspace.name/easycoding/1657)
本文对之前关于cookie的使用部分进行了修正。

# [python发送httpheader的http请求](http://www.findspace.name/easycoding/1137)
原来写的一篇水文。内容很少。
# 知乎上的一个问题

[如何应对网站反爬虫策略？如何高效地爬大量数据?](https://www.zhihu.com/question/28168585)
[一个有趣的回答（不是我的。。）](https://www.zhihu.com/question/28168585/answer/74840535)
